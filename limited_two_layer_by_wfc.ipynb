{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **気象予報データ全てを用いて翌日の05:30 ~ 18:30までの発電量をtwo_layerで予測する**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **必要な関数・ライブラリ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# データ加工・処理・分析モジュール\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "from two_layer import two_layer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_time(dataframe, col_name):\n",
    "    '''\n",
    "    to_datetimeを使うための前処理\n",
    "    '''\n",
    "    dataframe[col_name] = dataframe[col_name].map(lambda x : transform_time(x))\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_time(x):\n",
    "    '''\n",
    "    set_time内で使う関数\n",
    "    to_datetimeで24時をサポートしないので00に変更する処理\n",
    "    '''\n",
    "    str_x = str(x)\n",
    "    res = ''\n",
    "    if str(x)[8:10] == '24':\n",
    "        res = str_x[0:4] + '-' + str_x[4:6] + '-' + str_x[6:8] + ' 00:'+str_x[10:12] \n",
    "    else:\n",
    "        res = str_x[0:4] + '-' + str_x[4:6] + '-' + str_x[6:8] + ' '+ str_x[8:10] +':'+str_x[10:12]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_month_date(input_data, key=\"datetime\"):\n",
    "    '''\n",
    "    時間や月のデータを加える\n",
    "    '''\n",
    "    input_data['month'] = input_data[key].map(lambda x: int(x.month))\n",
    "    input_data['month_cos'] = input_data['month'].map(lambda x: np.cos(np.pi * x / 12))\n",
    "    input_data['month_sin'] = input_data['month'].map(lambda x: np.sin(np.pi * x / 12))\n",
    "    input_data = input_data.drop(['month'], axis=1)\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_30(tmp_data):\n",
    "    '''\n",
    "    必要なカラムだけ拾ってきて30分ごのデータに整形\n",
    "    '''\n",
    "    tmp_data = tmp_data[[\"datetime\", \"pr\", \"max_ws\", \"ave_ws\", \"max_tp\", \"min_tp\", \"sl\"]]\n",
    "    \n",
    "    # 欠損値を一つ前の値で置換/output_data\n",
    "    tmp_data = tmp_data.fillna(method='bfill')\n",
    "    tmp_30 = tmp_data.set_index('datetime').groupby(pd.TimeGrouper(freq='1800s', closed='left')).sum()\n",
    "\n",
    "    # datetimeのカラムを復活させる\n",
    "    tmp_30['datetime'] = tmp_30.index\n",
    "    tmp_30.index = np.arange(len(tmp_30))\n",
    "    tmp_30.head()\n",
    "    return tmp_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_output_data(Y):\n",
    "    '''\n",
    "    全時系列データから05:30 ~ 18:30までのデータごとに分割する\n",
    "    他のipynbとは違う関数であることに注意\n",
    "    発電量がないところはそもそも予測しないことにする\n",
    "    '''\n",
    "    output_list = []\n",
    "    # 一日は48個の時間帯に分けられる\n",
    "    total_size = len(Y) // 48\n",
    "    for i in range(total_size):\n",
    "        each_data = Y[(i*48+10):(i*48+37)]\n",
    "        reshaped = each_data.reshape(27)\n",
    "        output_list.append(list(reshaped))\n",
    "    output_list = np.array(output_list)\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_output_data(Y):\n",
    "    '''\n",
    "    取り除いて時間を足し戻す\n",
    "    返り値は一次元配列\n",
    "    '''\n",
    "    Y = np.array(Y)\n",
    "    Y_s = []\n",
    "    for i in range(len(Y)):\n",
    "        tmp = [0,0,0,0,0,0,0,0,0,0]+list(Y[i])+[0,0,0,0,0,0,0,0,0,0,0]\n",
    "        Y_s.append(tmp)\n",
    "    Y_s = np.array(Y_s)\n",
    "    Y_s = Y_s.reshape(Y_s.shape[0] *Y_s.shape[1])\n",
    "    return Y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_array(x):\n",
    "    '''\n",
    "    min, max, min-max正規化を行なった配列(np.array)を返す\n",
    "    '''\n",
    "    x = np.array(x)\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "    normalized = (x - x_min) / (x_max - x_min) \n",
    "    return x_min, x_max, normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def denormalize_array(normalized_x, x_min, x_max):\n",
    "    '''\n",
    "    正規化前のmin, maxを用いて元のスケールに戻す\n",
    "    '''\n",
    "    normalized_x = np.array(normalized_x)\n",
    "    denormalize_array = (normalized_x) * (x_max - x_min) + x_min\n",
    "    return denormalize_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_nan(X, Y):\n",
    "    '''\n",
    "    Yにnanが含まれるペアを削除(他のとこにあるdrop_nanとは別物なので注意)\n",
    "    '''\n",
    "    mask = []\n",
    "    for i in range(len(Y)):\n",
    "        if np.isnan(Y[i]).sum() == 0:\n",
    "            mask.append(True)\n",
    "        else:\n",
    "            mask.append(False)\n",
    "    X = X[mask]\n",
    "    Y = Y[mask]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_mae(X, Y):\n",
    "    '''\n",
    "    X, Yがメモリを食いすぎるのでfor文で計算\n",
    "    '''\n",
    "    mse = 0\n",
    "    for i in range(len(X)):\n",
    "        mse += np.abs(X[i]- Y[i])\n",
    "    return mse/len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wv_to_sin(x):\n",
    "    '''\n",
    "    漢字になってる風向データをsinになおす\n",
    "    '''\n",
    "    if x == \"北\":\n",
    "        return -1.0\n",
    "    elif x == \"北西\":\n",
    "        return -0.5\n",
    "    elif x == \"西\":\n",
    "        return 0.0\n",
    "    elif x == \"南西\":\n",
    "        return 0.5\n",
    "    elif x == \"南\":\n",
    "        return 1.0\n",
    "    elif x == \"南東\":\n",
    "        return 0.5\n",
    "    elif x == \"東\":\n",
    "        return 0\n",
    "    else:\n",
    "        return -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wv_to_cos(x):\n",
    "    '''\n",
    "    漢字になってる風向データをcosになおす\n",
    "    '''\n",
    "    \n",
    "    if x == \"北\":\n",
    "        return 0.0\n",
    "    elif x == \"北西\":\n",
    "        return 0.5\n",
    "    elif x == \"西\":\n",
    "        return 1.0\n",
    "    elif x == \"南西\":\n",
    "        return 0.5\n",
    "    elif x == \"南\":\n",
    "        return 0.0\n",
    "    elif x == \"南東\":\n",
    "        return -0.5\n",
    "    elif x == \"東\":\n",
    "        return -1.0\n",
    "    else:\n",
    "        return -0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **データの準備**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_place = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 発電量データ\n",
    "output_30 = pd.read_csv('data/processed_data/out_put.tsv', delimiter = '\\t')\n",
    "output_30['datetime'] = output_30['datetime'].map(lambda x : pd.to_datetime(x))\n",
    "output_30 = output_30[['datetime', 'SOLA0'+str(target_place)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 太陽電池の劣化に対応するためのスケーリング(必要かどうかはわからない)\n",
    "# 米倉山は欠損地が多いのでこれには適さない\n",
    "if target_place == 1 or target_place == 2:\n",
    "    output_30['year'] = output_30['datetime'].map(lambda x : x.year)\n",
    "    y_output = output_30.groupby(['year'], as_index=False).sum()\n",
    "    sum_2012 = y_output[\"SOLA0\"+str(target_place)][0]\n",
    "    sum_2013 = y_output[\"SOLA0\"+str(target_place)][1]\n",
    "    sum_2014 = y_output[\"SOLA0\"+str(target_place)][2]\n",
    "    sum_2015 = y_output[\"SOLA0\"+str(target_place)][3]\n",
    "    scaled_2012 = np.array(output_30[output_30['year'] == 2012][\"SOLA0\"+str(target_place)].map(lambda x : x * sum_2015/sum_2012))\n",
    "    scaled_2013 = np.array(output_30[output_30['year'] == 2013][\"SOLA0\"+str(target_place)].map(lambda x : x * sum_2015/sum_2013))\n",
    "    scaled_2014 = np.array(output_30[output_30['year'] == 2014][\"SOLA0\"+str(target_place)].map(lambda x : x * sum_2015/sum_2014))\n",
    "    scaled_2015 = np.array(output_30[output_30['year'] == 2015][\"SOLA0\"+str(target_place)])\n",
    "    tmp = np.r_[scaled_2012, scaled_2013, scaled_2014, scaled_2015]\n",
    "    output_30[\"SOLA0\"+str(target_place)] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 天気予報のデータを実は今まで使ってなかった\n",
    "if target_place == 1 or target_place == 2:\n",
    "    fc_data = pd.read_csv('data/raw_data/forecast_kanagawa.tsv', delimiter = '\\t')\n",
    "    fc_data['date'] = fc_data['date'].map(lambda x : pd.to_datetime(x))\n",
    "elif target_place == 3:\n",
    "    fc_data = pd.read_csv('data/raw_data/forecast_yamanashi.tsv', delimiter = '\\t')\n",
    "    fc_data['date'] = fc_data['date'].map(lambda x : pd.to_datetime(x))\n",
    "else:\n",
    "    raise ValueError(\"invalid input target_place\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各降水確率, 各時間帯の天気, 気温のみを選択\n",
    "fc_data = fc_data.drop(['weather', 'weather_detail', 'wind', 'wave'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "hours = ['we_00-03', 'we_03-06', 'we_06-09', 'we_09-12', 'we_12-15', 'we_15-18', 'we_18-21', 'we_21-24']\n",
    "for hour in hours:\n",
    "    dummy_df = pd.get_dummies(fc_data[[hour]])\n",
    "    fc_data = pd.concat([fc_data, dummy_df], axis=1, join='inner')\n",
    "    fc_data= fc_data.drop([hour], axis=1)\n",
    "hours = ['wv_00-03', 'wv_03-06', 'wv_06-09', 'wv_09-12', 'wv_12-15', 'wv_15-18', 'wv_18-21', 'wv_21-24']\n",
    "for hour in hours:\n",
    "    fc_data[hour+'_cos'] = fc_data[hour].map(lambda x:wv_to_cos(x))\n",
    "    fc_data[hour+'_sin'] = fc_data[hour].map(lambda x:wv_to_sin(x))\n",
    "    fc_data= fc_data.drop([hour], axis=1)\n",
    "    \n",
    "fc_with_date = add_month_date(fc_data, key=\"date\")\n",
    "'''\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_data[\"month\"] = fc_data[\"date\"].map(lambda x : str(x.month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sin cos を使わないやつ\n",
    "fc_data = pd.get_dummies(fc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pc_00-06</th>\n",
       "      <th>pc_06-12</th>\n",
       "      <th>pc_12-18</th>\n",
       "      <th>pc_18-24</th>\n",
       "      <th>wc_00-03</th>\n",
       "      <th>wc_03-06</th>\n",
       "      <th>wc_06-09</th>\n",
       "      <th>wc_09-12</th>\n",
       "      <th>wc_12-15</th>\n",
       "      <th>...</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "      <th>month_2</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_7</th>\n",
       "      <th>month_8</th>\n",
       "      <th>month_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  pc_00-06  pc_06-12  pc_12-18  pc_18-24  wc_00-03  wc_03-06  \\\n",
       "0 2012-01-01        30        30        10        30         2         2   \n",
       "1 2012-01-02        20        20        10        10         2         2   \n",
       "2 2012-01-03         0         0        10        10         4         4   \n",
       "3 2012-01-04        10        10        30        20         2         1   \n",
       "4 2012-01-05        10         0         0         0         4         4   \n",
       "\n",
       "   wc_06-09  wc_09-12  wc_12-15   ...     month_11  month_12  month_2  \\\n",
       "0         2         2         3   ...            0         0        0   \n",
       "1         3         4         4   ...            0         0        0   \n",
       "2         4         2         1   ...            0         0        0   \n",
       "3         2         2         2   ...            0         0        0   \n",
       "4         2         2         2   ...            0         0        0   \n",
       "\n",
       "   month_3  month_4  month_5  month_6  month_7  month_8  month_9  \n",
       "0        0        0        0        0        0        0        0  \n",
       "1        0        0        0        0        0        0        0  \n",
       "2        0        0        0        0        0        0        0  \n",
       "3        0        0        0        0        0        0        0  \n",
       "4        0        0        0        0        0        0        0  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデル構築のためにデータを分割する\n",
    "\n",
    "# 学習に必要なデータ\n",
    "# 前日の気象予報のデータで翌日の0:00 ~ 23:30を予測する\n",
    "train_x_s_idx = fc_data[fc_data['date'] == pd.to_datetime('2012-01-01')].index[0]\n",
    "train_x_e_idx = fc_data[fc_data['date'] == pd.to_datetime('2015-12-31')].index[0]\n",
    "train_y_s_idx = output_30[output_30['datetime'] == pd.to_datetime('2012-01-01 00:00')].index[0]\n",
    "train_y_e_idx = output_30[output_30['datetime'] == pd.to_datetime('2015-12-31 23:30')].index[0]\n",
    "\n",
    "output_kwh = output_30[\"SOLA0\"+str(target_place)][train_y_s_idx:train_y_e_idx+1]\n",
    "input_data = fc_data.drop([\"date\"], axis=1)[train_x_s_idx:train_x_e_idx+1]\n",
    "\n",
    "# 予測に必要なデータ\n",
    "# 前日の00:00 ~ 20:00のデータで翌日の0:00 ~ 23:30を予測する\n",
    "test_x_s_idx = fc_data[fc_data[\"date\"] == pd.to_datetime('2016-01-01')].index[0]\n",
    "test_x_e_idx = fc_data[fc_data[\"date\"] == pd.to_datetime('2017-3-31')].index[0]\n",
    "\n",
    "test_input_data = fc_data.drop([\"date\"], axis=1)[test_x_s_idx:test_x_e_idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MLPに突っ込むための準備をする\n",
    "\n",
    "# min-max正規化しておく\n",
    "normalized_input = (input_data - input_data.min()) / (input_data.max() - input_data.min())\n",
    "normalized_input = np.array(normalized_input)\n",
    "normalized_kwh = (output_kwh - output_kwh.min()) /(output_kwh.max() - output_kwh.min())\n",
    "normalized_kwh = np.array(normalized_kwh)\n",
    "\n",
    "# input_dataに関しては正規化すればそのまま使える\n",
    "input_list = normalized_input\n",
    "kwh_list = get_output_data(normalized_kwh)\n",
    "\n",
    "# outputがnanであれば取り除く\n",
    "filtered_input_list, filtered_kwh_list = drop_nan(input_list, kwh_list)\n",
    "\n",
    "# testデータの入力を用意\n",
    "normalized_test_input = (test_input_data - input_data.min()) / (input_data.max() - input_data.min())\n",
    "normalized_test_input = np.array(normalized_test_input)\n",
    "\n",
    "test_input_list = normalized_test_input\n",
    "\n",
    "# denormalize用\n",
    "kwh_max = float(output_kwh.max())\n",
    "kwh_min = float(output_kwh.min())\n",
    "\n",
    "# MLPに突っ込むためにデータを整形\n",
    "X = np.array(filtered_input_list).reshape(filtered_input_list.shape[0], filtered_input_list.shape[1])\n",
    "all_X = np.array(input_list).reshape(input_list.shape[0], input_list.shape[1])\n",
    "KWH = np.array(filtered_kwh_list).reshape(filtered_kwh_list.shape[0],filtered_kwh_list.shape[1])\n",
    "X_predict = np.array(test_input_list).reshape(test_input_list.shape[0], test_input_list.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **モデルの構築**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "条件:翌日の気温を予測するには前日の20:00までの気象情報しか使えない\n",
    "\n",
    "モデル:翌日の気象予報だけのデータで翌日の発電量を予測する\n",
    "\n",
    "入力:対象日の気象予報のデータ\n",
    "\n",
    "出力:0:00, 0:30, .... , 23:00, 23:30の気温の配列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, KWH, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory already exists\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "hidden_1 = 100\n",
    "hidden_2 = 100\n",
    "activation = \"tanh\"\n",
    "model_name = \"test\"\n",
    "try:\n",
    "    os.mkdir('./data/model/'+model_name)\n",
    "    print(\"make save directory\")\n",
    "except :\n",
    "    print(\"directory already exists\")\n",
    "\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_model = two_layer(X_train, Y_train, X_val, Y_val, epochs = epochs, hidden_1 = hidden_1, hidden_2 = hidden_2, batch_size = 100, model_name = model_name, activation = activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train#0, validation loss: 5.332498e-01\n",
      "train#20, validation loss: 4.231655e-02\n",
      "train#40, validation loss: 2.105108e-02\n",
      "train#60, validation loss: 2.138166e-02\n",
      "train#80, validation loss: 2.224123e-02\n",
      "train#100, validation loss: 1.690700e-02\n",
      "train#120, validation loss: 1.673371e-02\n",
      "train#140, validation loss: 1.715490e-02\n",
      "train#160, validation loss: 1.712967e-02\n",
      "train#180, validation loss: 1.722650e-02\n",
      "do early stopping\n"
     ]
    }
   ],
   "source": [
    "mlp_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "plt.plot([1.76E-02, 1.83E-02 ,1.83E-02, 1.91E-02, 1.67E-02, 1.70E-02, 1.67E-02, 1.64E-02, 1.80E-02, 1.69E-02, 1.77E-02, 1.80E-02, 1.88E-02, 2.01E-02, 1.96E-02, 2.00E-02, 2.06E-02, 2.10E-02, 2.29E-02])\n",
    "plt.xticks(np.arange(19), (np.arange(19)+1))\n",
    "plt.title(\"validation loss during training\")\n",
    "plt.xlabel(\"* 100 epochs\")\n",
    "'''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = mlp_model.predict(X)[0]\n",
    "processed_prediction = process_output_data(predictions)\n",
    "processed_prediction = denormalize_array(processed_prediction, kwh_min, kwh_max)\n",
    "\n",
    "true = process_output_data(filtered_kwh_list)\n",
    "true = denormalize_array(true, kwh_min, kwh_max)\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(processed_prediction[500:1000], label = \"prediction\")\n",
    "plt.plot(true[500:1000], label = \"true\")\n",
    "plt.legend()\n",
    "plt.title(\"predict kwh\")\n",
    "\n",
    "print('training mae :', calc_mae(processed_prediction, true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation = mlp_model.predict(mlp_model.X_val)[0]\n",
    "processed_validation = process_output_data(validation)\n",
    "processed_validation = denormalize_array(processed_validation, kwh_min, kwh_max)\n",
    "\n",
    "val = process_output_data(mlp_model.Y_val)\n",
    "val = denormalize_array(val, kwh_min, kwh_max)\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(processed_validation[500:1000], label = \"prediction\")\n",
    "plt.plot(val[500:1000], label = \"true\")\n",
    "plt.legend()\n",
    "plt.title(\"predict output\")\n",
    "\n",
    "print('validation mae :', calc_mae(processed_validation, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation mae : 162.182915965\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = mlp_model.predict(all_X)[0]\n",
    "processed_prediction = process_output_data(predictions)\n",
    "processed_prediction = denormalize_array(processed_prediction, kwh_min, kwh_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    predict_data = pd.read_csv('data/predicted_data/predict_train_SOLA0'+str(target_place)+'.tsv', delimiter='\\t')\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    s_idx = result[result['datetime'] == pd.to_datetime('2012/01/02 00:00')].index[0]\n",
    "    e_idx = result[result['datetime'] == pd.to_datetime('2015/12/31 23:30')].index[0]\n",
    "    predict_data = pd.DataFrame({\"datetime\":result['datetime'][s_idx:e_idx+1]})\n",
    "    predict_data.index = np.arange(len(predict_data))\n",
    "    predict_data.to_csv('data/predicted_data/predict_train_SOLA0'+str(target_place)+'.tsv', sep = '\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2012/01/02 00:00 ~ 2015/12/31 23:30の予測データを書き出す\n",
    "predict_data[model_name] = np.append(processed_prediction[48:-1], processed_prediction[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_data.to_csv('data/predicted_data/predict_train_SOLA0'+str(target_place)+'.tsv', sep = '\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_predictによる予測\n",
    "predictions = mlp_model.predict(X_predict)[0]\n",
    "processed_prediction = process_output_data(predictions)\n",
    "processed_prediction = denormalize_array(processed_prediction, kwh_min, kwh_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    predict_data = pd.read_csv('data/predicted_data/predict_SOLA0'+str(target_place)+'.tsv', delimiter='\\t')\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    s_idx = result[result['datetime'] == pd.to_datetime('2016/01/01 00:00')].index[0]\n",
    "    e_idx = result[result['datetime'] == pd.to_datetime('2017/3/31 23:30')].index[0]\n",
    "    predict_data = pd.DataFrame({\"datetime\":result['datetime'][s_idx:e_idx+1]})\n",
    "    predict_data.index = np.arange(len(predict_data))\n",
    "    predict_data.to_csv('data/predicted_data/predict_SOLA0'+str(target_place)+'.tsv', sep = '\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2016/01/01 00:00 ~ 2017/3/31 23:30の予測データを書き出す\n",
    "predict_data[model_name] = processed_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_data.to_csv('data/predicted_data/predict_SOLA0'+str(target_place)+'.tsv', sep = '\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# いろんなエポックのやつをまとめて学習して保存するやつ\n",
    "'''\n",
    "epochs = [500, 1000, 2000, 3000, 4000]\n",
    "for epoch in epochs:\n",
    "    \n",
    "    model_name = \"targetplace_\"+str(target_place)+\"_kwh_all_wfc_month_one_layer_hidden_50_\"+str(epoch)\n",
    "    \n",
    "    try:\n",
    "        os.mkdir('./data/model/'+model_name)\n",
    "        print(\"make save directory\")\n",
    "    except :\n",
    "        print(\"directory already exists\")\n",
    "\n",
    "    print(model_name) \n",
    "    \n",
    "    mlp_model = MLP.MLP(X, KWH, epochs = epoch, hidden_size = 50, batch_size = 100, model_name = model_name)\n",
    "    \n",
    "    mlp_model.train()\n",
    "    \n",
    "    predictions = mlp_model.predict(all_X)[0]\n",
    "    predictions = predictions.reshape(predictions.shape[0] * predictions.shape[1])\n",
    "    processed_prediction = denormalize_array(predictions, kwh_min, kwh_max)\n",
    "    \n",
    "    try:\n",
    "        predict_data = pd.read_csv('data/predicted_data/predict_train_SOLA0'+str(target_place)+'.tsv', delimiter='\\t')\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        s_idx = result[result['datetime'] == pd.to_datetime('2012/01/02 00:00')].index[0]\n",
    "        e_idx = result[result['datetime'] == pd.to_datetime('2015/12/31 23:30')].index[0]\n",
    "        predict_data = pd.DataFrame({\"datetime\":result['datetime'][s_idx:e_idx+1]})\n",
    "        predict_data.index = np.arange(len(predict_data))\n",
    "        predict_data.to_csv('data/predicted_data/predict_train_SOLA0'+str(target_place)+'.tsv', sep = '\\t', index=False)\n",
    "    \n",
    "    # 2012/01/02 00:00 ~ 2015/12/31 23:30の予測データを書き出す\n",
    "    predict_data[model_name] = np.append(processed_prediction[48:-1], processed_prediction[-1])\n",
    "    \n",
    "    # X_predictによる予測\n",
    "    predictions = mlp_model.predict(X_predict)[0]\n",
    "    predictions = predictions.reshape(predictions.shape[0] * predictions.shape[1])\n",
    "    processed_prediction = denormalize_array(predictions, kwh_min, kwh_max)\n",
    "    \n",
    "    try:\n",
    "        predict_data = pd.read_csv('data/predicted_data/predict_SOLA0'+str(target_place)+'.tsv', delimiter='\\t')\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        s_idx = result[result['datetime'] == pd.to_datetime('2016/01/01 00:00')].index[0]\n",
    "        e_idx = result[result['datetime'] == pd.to_datetime('2017/3/31 23:30')].index[0]\n",
    "        predict_data = pd.DataFrame({\"datetime\":result['datetime'][s_idx:e_idx+1]})\n",
    "        predict_data.index = np.arange(len(predict_data))\n",
    "        predict_data.to_csv('data/predicted_data/predict_SOLA0'+str(target_place)+'.tsv', sep = '\\t', index=False)\n",
    "    \n",
    "    # 2016/01/01 00:00 ~ 2017/3/31 23:30の予測データを書き出す\n",
    "    predict_data[model_name] = processed_prediction\n",
    "    \n",
    "    predict_data.to_csv('data/predicted_data/predict_SOLA0'+str(target_place)+'.tsv', sep = '\\t', index=False)\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# いろんな活性化関数を比べるためのやつ\n",
    "'''\n",
    "t_maes = []\n",
    "v_maes = []\n",
    "\n",
    "for i in range(5):\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X, KWH, test_size=0.33)\n",
    "    mlp_model = MLP(X_train, Y_train, X_val, Y_val, epochs = epochs, hidden_size = hidden_size, batch_size = 100, model_name = model_name, activation = activation)\n",
    "    mlp_model.train()\n",
    "    \n",
    "    predictions = mlp_model.predict(X)[0]\n",
    "    processed_prediction = process_output_data(predictions)\n",
    "    processed_prediction = denormalize_array(processed_prediction, kwh_min, kwh_max)\n",
    "    \n",
    "    true = process_output_data(filtered_kwh_list)\n",
    "    true = denormalize_array(true, kwh_min, kwh_max)\n",
    "    \n",
    "    t_maes.append(calc_mae(processed_prediction, true))\n",
    "    \n",
    "    validation = mlp_model.predict(mlp_model.X_val)[0]\n",
    "    processed_validation = process_output_data(validation)\n",
    "    processed_validation = denormalize_array(processed_validation, kwh_min, kwh_max)\n",
    "    \n",
    "    val = process_output_data(mlp_model.Y_val)\n",
    "    val = denormalize_array(val, kwh_min, kwh_max)\n",
    "    \n",
    "    v_maes.append(calc_mae(processed_validation, val))\n",
    "'''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory already exists\n",
      "targetplace_1_limited_scaled_kwh_all_wfc_sigmoid_hidden_100_1000_1-5folds\n",
      "train#0, validation loss: 8.082917e-01\n",
      "train#50, validation loss: 3.363991e-02\n",
      "train#100, validation loss: 2.046612e-02\n",
      "train#150, validation loss: 1.861351e-02\n",
      "train#200, validation loss: 1.871553e-02\n",
      "train#250, validation loss: 1.841954e-02\n",
      "train#300, validation loss: 1.821994e-02\n",
      "train#350, validation loss: 1.766363e-02\n",
      "train#400, validation loss: 1.794554e-02\n",
      "train#450, validation loss: 1.739469e-02\n",
      "train#500, validation loss: 1.730364e-02\n",
      "train#550, validation loss: 1.789586e-02\n",
      "train#600, validation loss: 1.711398e-02\n",
      "train#650, validation loss: 1.726789e-02\n",
      "train#700, validation loss: 1.734976e-02\n",
      "train#750, validation loss: 1.713007e-02\n",
      "train#800, validation loss: 1.728029e-02\n",
      "train#850, validation loss: 1.740671e-02\n",
      "do early stopping\n",
      "directory already exists\n",
      "targetplace_1_limited_scaled_kwh_all_wfc_sigmoid_hidden_100_1000_2-5folds\n",
      "train#0, validation loss: 4.955848e-01\n",
      "train#50, validation loss: 3.004701e-02\n",
      "train#100, validation loss: 1.900028e-02\n",
      "train#150, validation loss: 1.648535e-02\n",
      "train#200, validation loss: 1.643310e-02\n",
      "train#250, validation loss: 1.552631e-02\n",
      "train#300, validation loss: 1.567036e-02\n",
      "train#350, validation loss: 1.546875e-02\n",
      "train#400, validation loss: 1.497247e-02\n",
      "train#450, validation loss: 1.474087e-02\n",
      "train#500, validation loss: 1.502533e-02\n",
      "train#550, validation loss: 1.479893e-02\n",
      "train#600, validation loss: 1.565049e-02\n",
      "do early stopping\n",
      "directory already exists\n",
      "targetplace_1_limited_scaled_kwh_all_wfc_sigmoid_hidden_100_1000_3-5folds\n",
      "train#0, validation loss: 4.855198e-01\n",
      "train#50, validation loss: 3.239471e-02\n",
      "train#100, validation loss: 1.946322e-02\n",
      "train#150, validation loss: 1.724048e-02\n",
      "train#200, validation loss: 1.698151e-02\n",
      "train#250, validation loss: 1.665072e-02\n",
      "train#300, validation loss: 1.591527e-02\n",
      "train#350, validation loss: 1.579631e-02\n",
      "train#400, validation loss: 1.556699e-02\n",
      "train#450, validation loss: 1.550308e-02\n",
      "train#500, validation loss: 1.588315e-02\n",
      "do early stopping\n",
      "directory already exists\n",
      "targetplace_1_limited_scaled_kwh_all_wfc_sigmoid_hidden_100_1000_4-5folds\n",
      "train#0, validation loss: 2.953928e-01\n",
      "train#50, validation loss: 2.735015e-02\n",
      "train#100, validation loss: 1.797330e-02\n",
      "train#150, validation loss: 1.467896e-02\n",
      "train#200, validation loss: 1.463094e-02\n",
      "train#250, validation loss: 1.517547e-02\n",
      "train#300, validation loss: 1.369205e-02\n",
      "train#350, validation loss: 1.381908e-02\n",
      "train#400, validation loss: 1.399968e-02\n",
      "train#450, validation loss: 1.352770e-02\n",
      "train#500, validation loss: 1.354871e-02\n",
      "train#550, validation loss: 1.343045e-02\n",
      "train#600, validation loss: 1.562032e-02\n",
      "do early stopping\n",
      "directory already exists\n",
      "targetplace_1_limited_scaled_kwh_all_wfc_sigmoid_hidden_100_1000_5-5folds\n",
      "train#0, validation loss: 6.793900e-01\n",
      "train#50, validation loss: 3.552619e-02\n",
      "train#100, validation loss: 1.984180e-02\n",
      "train#150, validation loss: 1.865236e-02\n",
      "train#200, validation loss: 1.901845e-02\n",
      "train#250, validation loss: 1.740215e-02\n",
      "train#300, validation loss: 1.754927e-02\n",
      "train#350, validation loss: 1.747571e-02\n",
      "train#400, validation loss: 1.710965e-02\n",
      "train#450, validation loss: 1.938490e-02\n",
      "do early stopping\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# kfoldsでやるやつ\n",
    "\n",
    "epochs = 1000\n",
    "hidden_size = 100\n",
    "activation = \"sigmoid\"\n",
    "\n",
    "t_maes = []\n",
    "v_maes = []\n",
    "i = 0\n",
    "n_splits = 5\n",
    "\n",
    "for train_idx, test_idx in KFold(n_splits=n_splits).split(X):\n",
    "    X_train = X[train_idx]\n",
    "    Y_train = KWH[train_idx]\n",
    "    X_val = X[test_idx]\n",
    "    Y_val = KWH[test_idx]\n",
    "    \n",
    "    i += 1\n",
    "    model_name = \"targetplace_\"+str(target_place)+\"_limited_scaled_kwh_all_wfc_\"+activation\n",
    "    model_name += \"_hidden_\"+str(hidden_size)+\"_\"+str(epochs)\n",
    "    model_name += \"_\"+str(i)+\"-\"+str(n_splits)+\"folds\"\n",
    "    \n",
    "    try:\n",
    "        os.mkdir('./data/model/'+model_name)\n",
    "        print(\"make save directory\")\n",
    "    except :\n",
    "        print(\"directory already exists\")\n",
    "\n",
    "    print(model_name)\n",
    "    \n",
    "    mlp_model = MLP(X_train, Y_train, X_val, Y_val, epochs = epochs, hidden_size = hidden_size, batch_size = 100, model_name = model_name, activation = activation)\n",
    "\n",
    "    # train\n",
    "    mlp_model.train()\n",
    "    \n",
    "    # cal train mae\n",
    "    predictions = mlp_model.predict(X)[0]\n",
    "    processed_prediction = process_output_data(predictions)\n",
    "    processed_prediction = denormalize_array(processed_prediction, kwh_min, kwh_max)\n",
    "    \n",
    "    true = process_output_data(filtered_kwh_list)\n",
    "    true = denormalize_array(true, kwh_min, kwh_max)\n",
    "    \n",
    "    t_maes.append(calc_mae(processed_prediction, true))\n",
    "    \n",
    "    # calc validation mae\n",
    "    validation = mlp_model.predict(mlp_model.X_val)[0]\n",
    "    processed_validation = process_output_data(validation)\n",
    "    processed_validation = denormalize_array(processed_validation, kwh_min, kwh_max)\n",
    "    \n",
    "    Y_val = process_output_data(mlp_model.Y_val)\n",
    "    Y_val = denormalize_array(Y_val, kwh_min, kwh_max)\n",
    "    \n",
    "    v_maes.append(calc_mae(processed_validation, Y_val))\n",
    "    \n",
    "    # make train prediction data for stacking\n",
    "    predictions = mlp_model.predict(all_X)[0]\n",
    "    processed_prediction = process_output_data(predictions)\n",
    "    processed_prediction = denormalize_array(processed_prediction, kwh_min, kwh_max)\n",
    "    \n",
    "    try:\n",
    "        predict_data = pd.read_csv('data/predicted_data/predict_train_SOLA0'+str(target_place)+'.tsv', delimiter='\\t')\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        s_idx = result[result['datetime'] == pd.to_datetime('2012/01/02 00:00')].index[0]\n",
    "        e_idx = result[result['datetime'] == pd.to_datetime('2015/12/31 23:30')].index[0]\n",
    "        predict_data = pd.DataFrame({\"datetime\":result['datetime'][s_idx:e_idx+1]})\n",
    "        predict_data.index = np.arange(len(predict_data))\n",
    "        predict_data.to_csv('data/predicted_data/predict_train_SOLA0'+str(target_place)+'.tsv', sep = '\\t', index=False)\n",
    "        \n",
    "    # 2012/01/02 00:00 ~ 2015/12/31 23:30の予測データを書き出す\n",
    "    predict_data[model_name] = np.append(processed_prediction[48:-1], processed_prediction[-1])\n",
    "    predict_data.to_csv('data/predicted_data/predict_train_SOLA0'+str(target_place)+'.tsv', sep = '\\t', index=False)\n",
    "    \n",
    "    # X_predictによる予測\n",
    "    predictions = mlp_model.predict(X_predict)[0]\n",
    "    processed_prediction = process_output_data(predictions)\n",
    "    processed_prediction = denormalize_array(processed_prediction, kwh_min, kwh_max)\n",
    "    \n",
    "    try:\n",
    "        predict_data = pd.read_csv('data/predicted_data/predict_SOLA0'+str(target_place)+'.tsv', delimiter='\\t')\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        s_idx = result[result['datetime'] == pd.to_datetime('2016/01/01 00:00')].index[0]\n",
    "        e_idx = result[result['datetime'] == pd.to_datetime('2017/3/31 23:30')].index[0]\n",
    "        predict_data = pd.DataFrame({\"datetime\":result['datetime'][s_idx:e_idx+1]})\n",
    "        predict_data.index = np.arange(len(predict_data))\n",
    "        predict_data.to_csv('data/predicted_data/predict_SOLA0'+str(target_place)+'.tsv', sep = '\\t', index=False)\n",
    "    \n",
    "    # 2016/01/01 00:00 ~ 2017/3/31 23:30の予測データを書き出す\n",
    "    predict_data[model_name] = processed_prediction\n",
    "    predict_data.to_csv('data/predicted_data/predict_SOLA0'+str(target_place)+'.tsv', sep = '\\t', index=False)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nejOzjHPQm5llnIPezCzjHPRmZhn3/wGuqzROJ3HrmQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10dc84e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.plot(t_maes, 's', label=\"train_maes\")\n",
    "plt.plot(v_maes, 'D', label=\"validation_maes\")\n",
    "plt.legend()\n",
    "plt.title(\"each maes of \"+str(n_splits)+\" folds at target_place_\"+str(target_place))\n",
    "plt.xticks(np.arange(n_splits), np.arange(n_splits)+1)\n",
    "plt.show()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
