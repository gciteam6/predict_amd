{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **前日の20:00までのデータを用いて翌日の00:00~23:30までの発電量をそれぞれ弱学習機等で予測する**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **必要な関数・ライブラリ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# データ加工・処理・分析モジュール\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_time(dataframe, col_name):\n",
    "    '''\n",
    "    to_datetimeを使うための前処理\n",
    "    '''\n",
    "    dataframe[col_name] = dataframe[col_name].map(lambda x : transform_time(x))\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_time(x):\n",
    "    '''\n",
    "    set_time内で使う関数\n",
    "    to_datetimeで24時をサポートしないので00に変更する処理\n",
    "    '''\n",
    "    str_x = str(x)\n",
    "    res = ''\n",
    "    if str(x)[8:10] == '24':\n",
    "        res = str_x[0:4] + '-' + str_x[4:6] + '-' + str_x[6:8] + ' 00:'+str_x[10:12] \n",
    "    else:\n",
    "        res = str_x[0:4] + '-' + str_x[4:6] + '-' + str_x[6:8] + ' '+ str_x[8:10] +':'+str_x[10:12]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_datetime(x):\n",
    "    '''\n",
    "    指定されたdatetime形式になるように整形\n",
    "    '''\n",
    "    str_month = str(x.month)\n",
    "    if x.month - 10 < 0:\n",
    "        str_month = \"0\"+str(x.month)\n",
    "    str_day = str(x.day)\n",
    "    if x.day - 10 < 0:\n",
    "        str_day = \"0\"+str(x.day)\n",
    "    str_hour = str(x.hour)\n",
    "    if x.hour - 10 < 0:\n",
    "        str_hour = \"0\"+str(x.hour)\n",
    "    str_minute = str(x.minute)\n",
    "    if x.minute == 0:\n",
    "        str_minute = \"00\"\n",
    "    if x.minute == 0 and x.hour == 0:\n",
    "        str_minute = \"00\"\n",
    "        str_hour = \"24\"\n",
    "        str_day = str(x.day - 1)\n",
    "        if (x.day - 1) - 10 < 0:\n",
    "            str_day = \"0\"+str(x.day - 1)\n",
    "                              \n",
    "    return str(x.year)+str_month+str_day+str_hour+str_minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_hour_month(input_data):\n",
    "    '''\n",
    "    時間や月のデータを加える\n",
    "    '''\n",
    "    input_data['hour'] = input_data['datetime'].map(lambda x: int(x.hour))\n",
    "    input_data['minute'] = input_data['datetime'].map(lambda x: int(x.minute))\n",
    "    input_data['month'] = input_data['datetime'].map(lambda x: int(x.month))\n",
    "    input_data['month_cos'] = input_data['month'].map(lambda x: np.cos(np.pi * x / 12))\n",
    "    input_data['month_sin'] = input_data['month'].map(lambda x: np.sin(np.pi * x / 12))\n",
    "    input_data['hour_cos'] = input_data['hour'].map(lambda x: np.cos(np.pi * x / 24))\n",
    "    input_data['hour_sin'] = input_data['hour'].map(lambda x: np.sin(np.pi * x / 24))\n",
    "    input_data = input_data.drop(['hour', 'minute', 'month'], axis=1)\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_30(tmp_data):\n",
    "    '''\n",
    "    必要なカラムだけ拾ってきて30分ごのデータに整形\n",
    "    '''\n",
    "    tmp_data = tmp_data[[\"datetime\", \"pr\", \"max_ws\", \"ave_ws\", \"max_tp\", \"min_tp\", \"sl\"]]\n",
    "    \n",
    "    # 欠損値を一つ前の値で置換/output_data\n",
    "    tmp_data = tmp_data.fillna(method='bfill')\n",
    "    tmp_30 = tmp_data.set_index('datetime').groupby(pd.TimeGrouper(freq='1800s', closed='left')).sum()\n",
    "\n",
    "    # datetimeのカラムを復活させる\n",
    "    tmp_30['datetime'] = tmp_30.index\n",
    "    tmp_30.index = np.arange(len(tmp_30))\n",
    "    tmp_30.head()\n",
    "    return tmp_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_time_sincos(input_data):\n",
    "    '''\n",
    "    datetimeカラムがあることを前提に月時分の三角関数を足す\n",
    "    '''\n",
    "    input_data['hour'] = input_data['datetime'].map(lambda x: int(x.hour))\n",
    "    input_data['minute'] = input_data['datetime'].map(lambda x: int(x.minute))\n",
    "    input_data['month'] = input_data['datetime'].map(lambda x: int(x.month))\n",
    "    input_data['month_cos'] = input_data['month'].map(lambda x: np.cos(np.pi * x / 12))\n",
    "    input_data['month_sin'] = input_data['month'].map(lambda x: np.sin(np.pi * x / 12))\n",
    "    input_data['hour_cos'] = input_data['hour'].map(lambda x: np.cos(np.pi * x / 24))\n",
    "    input_data['hour_sin'] = input_data['hour'].map(lambda x: np.sin(np.pi * x / 24))\n",
    "    input_data['min_cos'] = input_data['minute'].map(lambda x: np.cos(np.pi * x / 60))\n",
    "    input_data['min_sin'] = input_data['minute'].map(lambda x: np.sin(np.pi * x / 60))\n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_array(x):\n",
    "    '''\n",
    "    min, max, min-max正規化を行なった配列(np.array)を返す\n",
    "    '''\n",
    "    x = np.array(x)\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "    normalized = (x - x_min) / (x_max - x_min) \n",
    "    return x_min, x_max, normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def denormalize_array(normalized_x, x_min, x_max):\n",
    "    '''\n",
    "    正規化前のmin, maxを用いて元のスケールに戻す\n",
    "    '''\n",
    "    normalized_x = np.array(normalized_x)\n",
    "    denormalize_array = (normalized_x) * (x_max - x_min) + x_min\n",
    "    return denormalize_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input_data(X):\n",
    "    '''\n",
    "    全時系列データから00:00 ~ 20:00までのデータごとに分割する\n",
    "    '''\n",
    "    input_list = []\n",
    "    # 一日は48個の時間帯に分けられる\n",
    "    total_size = len(X) // 48\n",
    "    reshaped_size = X[0:41].shape[0] * X[0:41].shape[1]\n",
    "    for i in range(total_size+1):\n",
    "        each_data = X[(i*48):(i*48+41)]\n",
    "        reshaped = each_data.reshape(reshaped_size)\n",
    "        input_list.append(list(reshaped))\n",
    "    input_list = np.array(input_list)\n",
    "    return input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_output_data(Y):\n",
    "    '''\n",
    "    全時系列データから00:00 ~ 23:30までのデータごとに分割する\n",
    "    '''\n",
    "    output_list = []\n",
    "    # 一日は48個の時間帯に分けられる\n",
    "    total_size = len(Y) // 48\n",
    "    for i in range(total_size):\n",
    "        each_data = Y[(i*48):(i*48+48)]\n",
    "        reshaped = each_data.reshape(48)\n",
    "        output_list.append(list(reshaped))\n",
    "    output_list = np.array(output_list)\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_nan(X, Y):\n",
    "    '''\n",
    "    Yにnanが含まれるペアを削除(他のとこにあるdrop_nanとは別物なので注意)\n",
    "    '''\n",
    "    mask = []\n",
    "    for i in range(len(Y)):\n",
    "        if np.isnan(Y[i]).sum() == 0:\n",
    "            mask.append(True)\n",
    "        else:\n",
    "            mask.append(False)\n",
    "    X = X[mask]\n",
    "    Y = Y[mask]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_mae(X, Y):\n",
    "    '''\n",
    "    X, Yがメモリを食いすぎるのでfor文で計算\n",
    "    '''\n",
    "    mse = 0\n",
    "    for i in range(len(X)):\n",
    "        mse += np.abs(X[i]- Y[i])\n",
    "    return mse/len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **データの準備**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_place = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 発電量データ\n",
    "output_30 = pd.read_csv('data/processed_data/out_put.tsv', delimiter = '\\t')\n",
    "output_30['datetime'] = output_30['datetime'].map(lambda x : pd.to_datetime(x))\n",
    "output_30 = output_30[['datetime', 'SOLA0'+str(target_place)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 天気予報のデータを実は今まで使ってなかった\n",
    "fc_data = pd.read_csv('data/raw_data/forecast_kanagawa.tsv', delimiter = '\\t')\n",
    "fc_data['date'] = fc_data['date'].map(lambda x : pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 各降水確率, 各時間帯の天気, 気温のみを選択\n",
    "fc_data = fc_data.drop(['weather', 'weather_detail', 'wind', 'wave', 'wv_00-03',\n",
    "       'wv_03-06', 'wv_06-09', 'wv_09-12', 'wv_12-15', 'wv_15-18', 'wv_18-21',\n",
    "       'wv_21-24', 'wc_00-03', 'wc_03-06', 'wc_06-09', 'wc_09-12', 'wc_12-15',\n",
    "       'wc_15-18', 'wc_18-21', 'wc_21-24'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hours = ['we_00-03', 'we_03-06', 'we_06-09', 'we_09-12', 'we_12-15', 'we_15-18', 'we_18-21', 'we_21-24']\n",
    "for hour in hours:\n",
    "    dummy_df = pd.get_dummies(fc_data[[hour]])\n",
    "    fc_data = pd.concat([fc_data, dummy_df], axis=1, join='inner')\n",
    "    fc_data= fc_data.drop([hour], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pc_00-06</th>\n",
       "      <th>pc_06-12</th>\n",
       "      <th>pc_12-18</th>\n",
       "      <th>pc_18-24</th>\n",
       "      <th>min_tp</th>\n",
       "      <th>max_tp</th>\n",
       "      <th>tp_00-03</th>\n",
       "      <th>tp_03-06</th>\n",
       "      <th>tp_06-09</th>\n",
       "      <th>...</th>\n",
       "      <th>we_15-18_雨</th>\n",
       "      <th>we_15-18_雪</th>\n",
       "      <th>we_18-21_くもり</th>\n",
       "      <th>we_18-21_晴れ</th>\n",
       "      <th>we_18-21_雨</th>\n",
       "      <th>we_18-21_雪</th>\n",
       "      <th>we_21-24_くもり</th>\n",
       "      <th>we_21-24_晴れ</th>\n",
       "      <th>we_21-24_雨</th>\n",
       "      <th>we_21-24_雪</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  pc_00-06  pc_06-12  pc_12-18  pc_18-24  min_tp  max_tp  \\\n",
       "0 2012-01-01        30        30        10        30       3      10   \n",
       "1 2012-01-02        20        20        10        10       5      11   \n",
       "2 2012-01-03         0         0        10        10       2       9   \n",
       "3 2012-01-04        10        10        30        20       2      10   \n",
       "4 2012-01-05        10         0         0         0       1       8   \n",
       "\n",
       "   tp_00-03  tp_03-06  tp_06-09     ...      we_15-18_雨  we_15-18_雪  \\\n",
       "0         5         4         4     ...               0           0   \n",
       "1         8         7         6     ...               0           0   \n",
       "2         4         3         3     ...               0           0   \n",
       "3         5         4         3     ...               0           0   \n",
       "4         3         2         1     ...               0           0   \n",
       "\n",
       "   we_18-21_くもり  we_18-21_晴れ  we_18-21_雨  we_18-21_雪  we_21-24_くもり  \\\n",
       "0             1            0           0           0             0   \n",
       "1             0            1           0           0             1   \n",
       "2             1            0           0           0             1   \n",
       "3             1            0           0           0             1   \n",
       "4             0            1           0           0             0   \n",
       "\n",
       "   we_21-24_晴れ  we_21-24_雨  we_21-24_雪  \n",
       "0            1           0           0  \n",
       "1            0           0           0  \n",
       "2            0           0           0  \n",
       "3            0           0           0  \n",
       "4            1           0           0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデル構築のためにデータを分割する\n",
    "\n",
    "# 学習に必要なデータ\n",
    "# 前日の00:00 ~ 20:00のデータで翌日の0:00 ~ 23:30を予測する\n",
    "train_x_s_idx = fc_data[fc_data['datetime'] == pd.to_datetime('2012-01-01 00:00')].index[0]\n",
    "train_x_e_idx = fc_data[fc_data['datetime'] == pd.to_datetime('2015-12-30 20:00')].index[0]\n",
    "train_y_s_idx = output_30[output_30['datetime'] == pd.to_datetime('2012-01-02 00:00')].index[0]\n",
    "train_y_e_idx = output_30[output_30['datetime'] == pd.to_datetime('2015-12-31 23:30')].index[0]\n",
    "\n",
    "output_kwh = output_30[\"SOLA0\"+str(target_place)][train_y_s_idx:train_y_e_idx+1]\n",
    "input_data = result.drop([\"datetime\"], axis=1)[train_x_s_idx:train_x_e_idx+1]\n",
    "# output_sl = target_30[\"sl\"][train_y_s_idx:train_y_e_idx+1]\n",
    "\n",
    "# 予測に必要なデータ\n",
    "# 前日の00:00 ~ 20:00のデータで翌日の0:00 ~ 23:30を予測する\n",
    "test_x_s_idx = result[result['datetime'] == pd.to_datetime('2015-12-31 00:00')].index[0]\n",
    "test_x_e_idx = result[result['datetime'] == pd.to_datetime('2017-3-30 20:00')].index[0]\n",
    "# test_y_s_idx = amd_30[amd_30['datetime'] == pd.to_datetime('2016-1-1 00:00')].index[0]\n",
    "# test_y_e_idx = amd_30[amd_30['datetime'] == pd.to_datetime('2017-3-31 23:30')].index[0]\n",
    "\n",
    "\n",
    "test_input_data = result.drop([\"datetime\"], axis=1)[test_x_s_idx:test_x_e_idx+1]\n",
    "# test_output_sl = target_30[[\"sl\"]][test_y_s_idx:test_y_e_idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MLPに突っ込むための準備をする\n",
    "\n",
    "# min-max正規化しておく\n",
    "normalized_input = (input_data - input_data.min()) / (input_data.max() - input_data.min())\n",
    "normalized_input = np.array(normalized_input)\n",
    "normalized_kwh = (output_kwh - output_kwh.min()) /( output_kwh.max() - output_kwh.min())\n",
    "normalized_kwh = np.array(normalized_kwh)\n",
    "# normalized_output = (output_sl - output_sl.min()) / (output_sl.max() - output_sl.min())\n",
    "# normalized_output = np.array(normalized_output)\n",
    "\n",
    "input_list = get_input_data(normalized_input)\n",
    "kwh_list = get_output_data(normalized_kwh)\n",
    "# output_list = get_output_data(normalized_output)\n",
    "\n",
    "filtered_input_list, filtered_kwh_list = drop_nan(input_list, kwh_list)\n",
    "\n",
    "# testデータの入力を用意\n",
    "normalized_test_input = (test_input_data - test_input_data.min()) / (test_input_data.max() - test_input_data.min())\n",
    "normalized_test_input = np.array(normalized_test_input)\n",
    "\n",
    "test_input_list = get_input_data(normalized_test_input)\n",
    "\n",
    "# denormalize用\n",
    "kwh_max = float(output_kwh.max())\n",
    "kwh_min = float(output_kwh.min())\n",
    "# output_max = float(output_sl.max())\n",
    "# output_min = float(output_sl.min())\n",
    "\n",
    "# MLPに突っ込むためにデータを整形\n",
    "X = np.array(filtered_input_list).reshape(filtered_input_list.shape[0], filtered_input_list.shape[1])\n",
    "all_X = np.array(input_list).reshape(input_list.shape[0], input_list.shape[1])\n",
    "KWH = np.array(filtered_kwh_list).reshape(filtered_kwh_list.shape[0],filtered_kwh_list.shape[1])\n",
    "X_predict = np.array(test_input_list).reshape(test_input_list.shape[0], test_input_list.shape[1])\n",
    "# Y = np.array(normalized_output).reshape(output_list.shape[0], output_list.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **モデルの構築**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "条件:翌日の気温を予測するには前日の20:00までの気象情報しか使えない\n",
    "\n",
    "モデル:翌日の30分毎の気温を前日の20:00までの各所のアメダスの気象情報で予測させる\n",
    "\n",
    "入力:各所のアメダス情報をひとまとめにした配列\n",
    "\n",
    "出力:0:00, 0:30, .... , 23:00, 23:30の気温の配列\n",
    "\n",
    "とりあえず一つの箇所のデータを使って予測\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 発電所近くのamedas\n",
    "# アメダスデータの読み込み\n",
    "if target_place == 1 or target_place == 2:\n",
    "    # 対象アメダスは横浜アメダス, amd_46106\n",
    "    # 各amdidはamd_masterに記載されている\n",
    "    target_amd_data = pd.read_csv('data/raw_data/amd_46106.tsv', delimiter = '\\t')\n",
    "    target_amd_data = set_time(target_amd_data, 'datetime')\n",
    "    target_amd_data['datetime'] = target_amd_data['datetime'].map(lambda x : pd.to_datetime(x))\n",
    "elif target_place == 3:\n",
    "    # 甲府アメダスのデータを使って予測する, amd_49142\n",
    "    # 各amdidはamd_masterに記載されている\n",
    "    target_amd_data = pd.read_csv('data/raw_data/amd_49142.tsv', delimiter = '\\t')\n",
    "    target_amd_data = set_time(target_amd_data, 'datetime')\n",
    "    target_amd_data['datetime'] = target_amd_data['datetime'].map(lambda x : pd.to_datetime(x))\n",
    "else:\n",
    "    raise ValueError(\"invalid input target_place\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 欠損値を一つ前の値で置換/output_data\n",
    "target_amd_data = target_amd_data.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "suffix = 1\n",
    "result = get_30(target_amd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 名古屋アメダスのデータを使って予測する, amd_51106\n",
    "# 各amdidはamd_masterに記載されている\n",
    "tmp_data = pd.read_csv('data/raw_data/amd_51106.tsv', delimiter = '\\t')\n",
    "tmp_data = set_time(tmp_data, 'datetime')\n",
    "tmp_data['datetime'] = tmp_data['datetime'].map(lambda x : pd.to_datetime(x))    \n",
    "tmp_30 = get_30(tmp_data)\n",
    "result = pd.merge(tmp_30, result, on='datetime', suffixes = ('_'+str(suffix), '_'+str(suffix+1)))\n",
    "suffix += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data = result[['datetime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyojin/anaconda/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/Users/kyojin/anaconda/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/kyojin/anaconda/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/Users/kyojin/anaconda/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/kyojin/anaconda/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/kyojin/anaconda/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/kyojin/anaconda/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/kyojin/anaconda/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/kyojin/anaconda/envs/tf/lib/python3.5/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# 時間の情報\n",
    "input_data = add_time_sincos(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 浜松のデータamd_50456を加える\n",
    "tmp_data = pd.read_csv('data/raw_data/amd_50456.tsv', delimiter = '\\t')\n",
    "tmp_data = set_time(tmp_data, 'datetime')\n",
    "tmp_data['datetime'] = tmp_data['datetime'].map(lambda x : pd.to_datetime(x))\n",
    "tmp_30 = get_30(tmp_data)\n",
    "result = pd.merge(result, tmp_30, on='datetime', suffixes = ('_'+str(suffix), '_'+str(suffix+1)))\n",
    "suffix += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 大阪のデータamd_62078を加える\n",
    "tmp_data = pd.read_csv('data/raw_data/amd_50456.tsv', delimiter = '\\t')\n",
    "tmp_data = set_time(tmp_data, 'datetime')\n",
    "tmp_data['datetime'] = tmp_data['datetime'].map(lambda x : pd.to_datetime(x))\n",
    "tmp_30 = get_30(tmp_data)\n",
    "result = pd.merge(result, tmp_30, on='datetime', suffixes = ('_'+str(suffix), '_'+str(suffix+1)))\n",
    "suffix += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 飯田のデータamd_62078を加える\n",
    "tmp_data = pd.read_csv('data/raw_data/amd_48767.tsv', delimiter = '\\t')\n",
    "tmp_data = set_time(tmp_data, 'datetime')\n",
    "tmp_data['datetime'] = tmp_data['datetime'].map(lambda x : pd.to_datetime(x))\n",
    "tmp_30 = get_30(tmp_data)\n",
    "result = pd.merge(result, tmp_30, on='datetime', suffixes = ('_'+str(suffix), '_'+str(suffix+1)))\n",
    "suffix += 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
